{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Sequence-to-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одним из возможных способов улучшения качества системы распознавания рукописных документов является пост-обработка предиктов с помощью модели sequence-to-sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "### В качестве дополнительных данных для обучения модели можно использовать коллекцию текстов 17 века, которая была предложена организаторами соревнования GramEval2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/home/jovyan/grameval_17_century.txt\"\n",
    "\n",
    "\n",
    "def read_grameval(fname=fname):\n",
    "    with open(fname, \"r\", encoding='utf-8') as f:\n",
    "        lines = [x[:-1] for x in f.readlines()]\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grameval_texts = read_grameval(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и то явное ихъ съ откащикомъ воровство не поставя столба въ отказные книги за споромъ чювашина бортнички написали'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grameval_texts[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зададим набор правил для аугментации данных с использованием шума и специфики стиля Петра I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# p of substitution = 1/znam\n",
    "znam = 2\n",
    "\n",
    "rules = []\n",
    "\n",
    "#Традиционно над строкой Петр пишет «з» и «с», конечное «х», также «к» перед широкой размашистой «ж»\n",
    "rules.append(('з',''))\n",
    "rules.append(('c',''))\n",
    "rules.append(('x',''))\n",
    "rules.append(('кж', 'ж'))\n",
    "#вместо старого «ѧ» уже регулярно употребляет вполне современное «я»\n",
    "rules.append(('ѧ', 'я'))\n",
    "#Не любит буквы «s» («зело») и «ѵ» \n",
    "rules.append(('s', ''))\n",
    "rules.append(('ѵ', ''))\n",
    "#Мягкий знак пропускает\n",
    "rules.append(('ь', ''))\n",
    "\n",
    "\n",
    "def replace_letters(line, to_replace, replace_by, znam=2):\n",
    "    new_line = ''\n",
    "    for letter in line:\n",
    "        if letter == to_replace and random.randint(0, znam - 1) % znam == 0:\n",
    "            new_line = new_line + replace_by\n",
    "        else:\n",
    "            new_line = new_line + letter\n",
    "    return new_line\n",
    "    \n",
    "\n",
    "def apply_rule(lines, rule, znam=2):\n",
    "    to_replace, replace_by = rule\n",
    "    res = [\n",
    "        replace_letters(line, to_replace, replace_by) for line in lines\n",
    "    ]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter's writing rules:\n",
      "[('з', ''), ('c', ''), ('x', ''), ('кж', 'ж'), ('ѧ', 'я'), ('s', ''), ('ѵ', ''), ('ь', '')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Peter's writing rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "for rule in tqdm(rules, total=len(rules), desc=\"Generating data...\"):\n",
    "    grameval_texts = apply_rule(grameval_texts, rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачаем обучающую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-21 18:31:12--  https://storage.yandexcloud.net/datasouls-ods/materials/46b7bb85/datasets.zip\n",
      "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
      "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 640106308 (610M) [application/zip]\n",
      "Saving to: ‘datasets.zip’\n",
      "\n",
      "datasets.zip        100%[===================>] 610.45M  41.0MB/s    in 14s     \n",
      "\n",
      "2020-10-21 18:31:28 (43.4 MB/s) - ‘datasets.zip’ saved [640106308/640106308]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://storage.yandexcloud.net/datasouls-ods/materials/46b7bb85/datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir aij_data\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(\"datasets.zip\", \"r\") as f:\n",
    "    f.extractall(\"aij_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим словарь для генерации шума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "trans_dir = '/home/jovyan/aij_data/train/words'\n",
    "image_dir = '/home/jovyan/aij_data/train/images'\n",
    "\n",
    "english = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'm', 'n' ,'o', 'p', 'r', 's', 't', 'u', 'w']\n",
    "\n",
    "\n",
    "def process_texts(image_dir, trans_dir):\n",
    "    lens = []\n",
    "    include_english = 0\n",
    "    letters = ''\n",
    "\n",
    "    lines = []\n",
    "    names = []\n",
    "    \n",
    "    all_files = os.listdir(trans_dir)\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename[:-3]+'txt' in all_files:\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            txt_filepath = os.path.join(trans_dir, name + '.txt')\n",
    "            with open(txt_filepath, 'r') as file:\n",
    "                data = file.read()\n",
    "                if len(data)==0:\n",
    "                    continue\n",
    "                if len(set(data).intersection(english))>0:\n",
    "                    continue\n",
    "\n",
    "                lines.append(data)\n",
    "                names.append(filename)\n",
    "                lens.append(len(data))\n",
    "                letters += data\n",
    "\n",
    "    print('Максимальная длина строки:', max(lens))\n",
    "    print('Количество строк с английскими буквами ', include_english)\n",
    "\n",
    "    return names, lines, Counter(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина строки: 71\n",
      "Количество строк с английскими буквами  0\n"
     ]
    }
   ],
   "source": [
    "names, lines, cnt = process_texts(image_dir,trans_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Символы train:   ) + / 0 1 2 3 4 5 6 7 8 9 [ ] i k l | × ǂ а б в г д е ж з и й к л м н о п р с т у ф х ц ч ш щ ъ ы ь э ю я і ѣ – … ⊕ ⊗\n"
     ]
    }
   ],
   "source": [
    "letters = sorted(list(cnt.keys()))\n",
    "print('Символы train:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример аугментации\n",
    "\n",
    "* добавление шума из словаря на посимвольном уровне;\n",
    "* удаление пробелов с определенной вероятностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(lines + grameval_texts, columns=[\"trg\"])\n",
    "\n",
    "def add_noise(text, symbols=letters, znam=4):\n",
    "    text = list(text)\n",
    "    num = len(text) // znam\n",
    "    indexes = random.sample(range(0, len(text)), num)\n",
    "    for i in indexes:\n",
    "        if text[i]!=' ':\n",
    "            text[i] = random.choice(symbols)\n",
    "        else:\n",
    "            del_space = np.random.choice([True, False], p=[0.3, 0.7])\n",
    "            if del_space:\n",
    "                text[i] = text[i].replace(\" \", \"\")\n",
    "    return ''.join(text)\n",
    "\n",
    "\n",
    "df[\"src\"] = [add_noise(t, znam=4) for t in df[\"trg\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trg</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>развѣ кромѣ на то развѣ на наше вой</td>\n",
       "      <td>8агвѣ кромѣ ѣа то ржзвѣ на н–ше 7щй</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>такой когда бывает осен то по феся годы выду</td>\n",
       "      <td>тад0й когда бы[ае3 осзн то по фесп гнеы выду</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>г подпол</td>\n",
       "      <td>г м]дпол</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>дению есть  [i чтоб не iзволил слабѣт в при</td>\n",
       "      <td>иению есть  [г 7тоб ме i⊕вмлилслдбѣ7 в пби</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>по крылам перебиратца</td>\n",
       "      <td>по крыла+ пиаебирітжа</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            trg  \\\n",
       "0           развѣ кромѣ на то развѣ на наше вой   \n",
       "1  такой когда бывает осен то по феся годы выду   \n",
       "2                                      г подпол   \n",
       "3   дению есть  [i чтоб не iзволил слабѣт в при   \n",
       "4                         по крылам перебиратца   \n",
       "\n",
       "                                            src  \n",
       "0           8агвѣ кромѣ ѣа то ржзвѣ на н–ше 7щй  \n",
       "1  тад0й когда бы[ае3 осзн то по фесп гнеы выду  \n",
       "2                                      г м]дпол  \n",
       "3    иению есть  [г 7тоб ме i⊕вмлилслдбѣ7 в пби  \n",
       "4                         по крыла+ пиаебирітжа  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем заранее аугментированные данные, где:\n",
    "\n",
    "* id – id семпла;\n",
    "* src – исходная последовательность;\n",
    "* trg – целевая последовательность;\n",
    "* cn – длина исходной последовательности в символах.\n",
    "\n",
    "Датафрейм включает в себя аугментацию предиктов бейзлайна на валидационном сете (```baseline.ipynb```) и предложений из ```grameval_17_century.txt```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>cn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304337</th>\n",
       "      <td>400047</td>\n",
       "      <td>по указу великаго государя т иъ моностырского ...</td>\n",
       "      <td>по указу великаго государя т изъ моностырьског...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182797</th>\n",
       "      <td>256232</td>\n",
       "      <td>потиръ олотъ гладкой вѣсу въ нем 3 гривенки</td>\n",
       "      <td>потиръ золотъ гладкой вѣсу въ нем 3 гривенки</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309834</th>\n",
       "      <td>406537</td>\n",
       "      <td>и борисъ съ ними ѣхали на подхожей станъ и не ...</td>\n",
       "      <td>и борисъ съ ними ѣхали на подхожей станъ и не ...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28951</th>\n",
       "      <td>40569</td>\n",
       "      <td>с достпканца  божечко9</td>\n",
       "      <td>2 достоканца  бочечкою</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204573</th>\n",
       "      <td>281979</td>\n",
       "      <td>отъ перваго же  авраамля и до исходъ моисеева ...</td>\n",
       "      <td>отъ перваго же  авраамля и до исхода моисеева ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                src  \\\n",
       "304337  400047  по указу великаго государя т иъ моностырского ...   \n",
       "182797  256232        потиръ олотъ гладкой вѣсу въ нем 3 гривенки   \n",
       "309834  406537  и борисъ съ ними ѣхали на подхожей станъ и не ...   \n",
       "28951    40569                             с достпканца  божечко9   \n",
       "204573  281979  отъ перваго же  авраамля и до исходъ моисеева ...   \n",
       "\n",
       "                                                      trg  cn  \n",
       "304337  по указу великаго государя т изъ моностырьског...  98  \n",
       "182797       потиръ золотъ гладкой вѣсу въ нем 3 гривенки  43  \n",
       "309834  и борисъ съ ними ѣхали на подхожей станъ и не ...  80  \n",
       "28951                              2 достоканца  бочечкою  22  \n",
       "204573  отъ перваго же  авраамля и до исхода моисеева ...  65  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/jovyan/augmented_data.csv\", sep=\",\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 1: Базовая модель Encoder-Decoder with Bahdanau Attention\n",
    "\n",
    "##### На основе https://bastings.github.io/annotated_encoder_decoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --quiet python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from IPython.core.debugger import set_trace\n",
    "import Levenshtein as lev\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda:0')\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
    "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
    "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
    "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
    "\n",
    "    def encode(self, src, src_mask, src_lengths):\n",
    "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        encoder_hidden,\n",
    "        encoder_final,\n",
    "        src_mask,\n",
    "        trg,\n",
    "        trg_mask,\n",
    "        decoder_hidden=None,\n",
    "    ):\n",
    "        return self.decoder(\n",
    "            self.trg_embed(trg),\n",
    "            encoder_hidden,\n",
    "            encoder_final,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            hidden=decoder_hidden,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Applies a bidirectional GRU to sequence of embeddings x.\n",
    "        The input mini-batch x needs to be sorted by length.\n",
    "        x should have dimensions [batch, time, dim].\n",
    "        \"\"\"\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        output, final = self.rnn(packed)\n",
    "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        # we need to manually concatenate the final states for both directions\n",
    "        fwd_final = final[0 : final.size(0) : 2]\n",
    "        bwd_final = final[1 : final.size(0) : 2]\n",
    "        # [num_layers, batch, 2*dim]\n",
    "        final = torch.cat([fwd_final, bwd_final], dim=2)\n",
    "\n",
    "        return output, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5, bridge=True\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention = attention\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            emb_size + 2 * hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # to initialize from the final encoder state\n",
    "        self.bridge = (\n",
    "            nn.Linear(2 * hidden_size, hidden_size, bias=True) if bridge else None\n",
    "        )\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.pre_output_layer = nn.Linear(\n",
    "            hidden_size + 2 * hidden_size + emb_size, hidden_size, bias=False\n",
    "        )\n",
    "\n",
    "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
    "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
    "\n",
    "        # compute context vector using attention mechanism\n",
    "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
    "        context, attn_probs = self.attention(\n",
    "            query=query, proj_key=proj_key, value=encoder_hidden, mask=src_mask\n",
    "        )\n",
    "\n",
    "        # update rnn hidden state\n",
    "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "\n",
    "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
    "        pre_output = self.dropout_layer(pre_output)\n",
    "        pre_output = self.pre_output_layer(pre_output)\n",
    "\n",
    "        return output, hidden, pre_output\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        trg_embed,\n",
    "        encoder_hidden,\n",
    "        encoder_final,\n",
    "        src_mask,\n",
    "        trg_mask,\n",
    "        hidden=None,\n",
    "        max_len=None,\n",
    "    ):\n",
    "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
    "\n",
    "        # the maximum number of steps to unroll the RNN\n",
    "        if max_len is None:\n",
    "            max_len = trg_mask.size(-1)\n",
    "\n",
    "        # initialize decoder hidden state\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(encoder_final)\n",
    "\n",
    "        # pre-compute projected encoder hidden states\n",
    "        # (the \"keys\" for the attention mechanism)\n",
    "        # this is only done for efficiency\n",
    "        proj_key = self.attention.key_layer(encoder_hidden)\n",
    "\n",
    "        # here we store all intermediate hidden states and pre-output vectors\n",
    "        decoder_states = []\n",
    "        pre_output_vectors = []\n",
    "\n",
    "        # unroll the decoder RNN for max_len steps\n",
    "        for i in range(max_len):\n",
    "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
    "            output, hidden, pre_output = self.forward_step(\n",
    "                prev_embed, encoder_hidden, src_mask, proj_key, hidden\n",
    "            )\n",
    "            decoder_states.append(output)\n",
    "            pre_output_vectors.append(pre_output)\n",
    "\n",
    "        decoder_states = torch.cat(decoder_states, dim=1)\n",
    "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
    "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
    "\n",
    "    def init_hidden(self, encoder_final):\n",
    "        \"\"\"Returns the initial decoder state,\n",
    "        conditioned on the final encoder state.\"\"\"\n",
    "\n",
    "        if encoder_final is None:\n",
    "            return None  # start with zeros\n",
    "\n",
    "        return torch.tanh(self.bridge(encoder_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "\n",
    "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "        # to store attention scores\n",
    "        self.alphas = None\n",
    "\n",
    "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
    "        assert mask is not None, \"mask is required\"\n",
    "\n",
    "        # We first project the query (the decoder state).\n",
    "        # The projected keys (the encoder states) were already pre-computated.\n",
    "        query = self.query_layer(query)\n",
    "\n",
    "        # Calculate scores.\n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        # Mask out invalid positions.\n",
    "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
    "        scores.data.masked_fill_(mask == 0, -float(\"inf\"))\n",
    "\n",
    "        # Turn scores to probabilities.\n",
    "        alphas = F.softmax(scores, dim=-1)\n",
    "        self.alphas = alphas\n",
    "\n",
    "        # The context vector is the weighted sum of the values.\n",
    "        context = torch.bmm(alphas, value)\n",
    "\n",
    "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
    "        return context, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, trg, pad_index=0):\n",
    "\n",
    "        src, src_lengths = src\n",
    "\n",
    "        self.src = src\n",
    "        self.src_lengths = src_lengths\n",
    "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
    "        self.nseqs = src.size(0)\n",
    "\n",
    "        self.trg = None\n",
    "        self.trg_y = None\n",
    "        self.trg_mask = None\n",
    "        self.trg_lengths = None\n",
    "        self.ntokens = None\n",
    "\n",
    "        if trg is not None:\n",
    "            trg, trg_lengths = trg\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_lengths = trg_lengths\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = self.trg_y != pad_index\n",
    "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
    "\n",
    "        if USE_CUDA:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "\n",
    "            if trg is not None:\n",
    "                self.trg = self.trg.cuda()\n",
    "                self.trg_y = self.trg_y.cuda()\n",
    "                self.trg_mask = self.trg_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(\n",
    "            x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "        )\n",
    "        loss = loss / norm\n",
    "\n",
    "        if self.opt is not None:\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "        return loss.data.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "\n",
    "    attention = BahdanauAttention(hidden_size)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(\n",
    "            emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout\n",
    "        ),\n",
    "        nn.Embedding(src_vocab, emb_size),\n",
    "        nn.Embedding(tgt_vocab, emb_size),\n",
    "        Generator(hidden_size, tgt_vocab),\n",
    "    )\n",
    "\n",
    "    return model.cuda() if USE_CUDA else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(\n",
    "    example_iter,\n",
    "    model,\n",
    "    n=2,\n",
    "    max_len=256,\n",
    "    src_vocab=None,\n",
    "    trg_vocab=None,\n",
    "):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "\n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    for i, batch in enumerate(example_iter):\n",
    "\n",
    "        src = batch.src.cpu().numpy()[0, :]\n",
    "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
    "\n",
    "        src = src[:-1] if src[-1] == src_eos_index else src\n",
    "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg\n",
    "\n",
    "        result, _ = greedy_decode(\n",
    "            model,\n",
    "            batch.src,\n",
    "            batch.src_mask,\n",
    "            batch.src_lengths,\n",
    "            max_len=max_len,\n",
    "            sos_index=trg_sos_index,\n",
    "            eos_index=trg_eos_index,\n",
    "        )\n",
    "        print(\"Example #%d\" % (i + 1))\n",
    "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
    "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
    "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
    "        print()\n",
    "\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return list(text)\n",
    "\n",
    "\n",
    "PAD_TOKEN = \"{\"\n",
    "SOS_TOKEN = \"~\"\n",
    "EOS_TOKEN = \"^\"\n",
    "UNK_TOKEN = \"&\"\n",
    "\n",
    "\n",
    "ID = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "SOURCE = data.Field(\n",
    "    tokenize=tokenize,\n",
    "    batch_first=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    init_token=None,\n",
    "    eos_token=EOS_TOKEN,\n",
    ")\n",
    "\n",
    "TARGET = data.Field(\n",
    "    tokenize=tokenize,\n",
    "    batch_first=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    init_token=SOS_TOKEN,\n",
    "    eos_token=EOS_TOKEN,\n",
    ")\n",
    "\n",
    "LEN = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "data_fields = [(\"id\", ID), (\"src\", SOURCE), (\"trg\", TARGET), (\"cn\", LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "encoder_decoder_model_path = \"encoder_decoder_model\"\n",
    "\n",
    "\n",
    "if not os.path.exists(encoder_decoder_model_path):\n",
    "    os.makedirs(encoder_decoder_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/jovyan/augmented_data.csv\"\n",
    "\n",
    "encoder_decoder_data = data.TabularDataset(\n",
    "    path=data_path, format=\"csv\", skip_header=True, fields=data_fields\n",
    ")\n",
    "\n",
    "train_data, dev_data = encoder_decoder_data.split(\n",
    "    split_ratio=[0.9, 0.1], stratified=True, strata_field=\"cn\"\n",
    ")\n",
    "\n",
    "SOURCE.build_vocab(train_data.src)\n",
    "TARGET.build_vocab(train_data.trg)\n",
    "PAD_INDEX = TARGET.vocab.stoi[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_iter = data.BucketIterator(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "    repeat=False,\n",
    "    device=DEVICE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_iter_batch = data.Iterator(\n",
    "    dev_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train=False,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "    repeat=False,\n",
    "    device=DEVICE,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebatch(pad_idx, batch):\n",
    "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
    "    return Batch(batch.src, batch.trg, pad_idx)\n",
    "\n",
    "\n",
    "def run_epoch(data_iter, model, loss_compute, print_every=50, num_batches=100):\n",
    "    \"\"\"Standard Training and Logging Function\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    print_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(data_iter, 1):\n",
    "\n",
    "            out, _, pre_output = model.forward(\n",
    "                batch.src,\n",
    "                batch.trg,\n",
    "                batch.src_mask,\n",
    "                batch.trg_mask,\n",
    "                batch.src_lengths,\n",
    "                batch.trg_lengths,\n",
    "            )\n",
    "            loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
    "            total_loss += loss\n",
    "            print_tokens += batch.ntokens\n",
    "            total_tokens += batch.ntokens\n",
    "\n",
    "            if model.training and i % print_every == 0:\n",
    "                elapsed = time.time() - start\n",
    "                print(\n",
    "                    \"Epoch Step: %d Loss: %f Tokens per Sec: %f\"\n",
    "                    % (i, loss / batch.nseqs, print_tokens / elapsed)\n",
    "                )\n",
    "                start = time.time()\n",
    "                print_tokens = 0\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    loss = total_loss / float(total_tokens)\n",
    "    perplexity = math.exp(loss)\n",
    "\n",
    "    return perplexity, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(batch, vocab, target=True):\n",
    "    res = []\n",
    "    eos_index = vocab.stoi[EOS_TOKEN]\n",
    "    batch = batch.trg.tolist() if target else batch.src.tolist()\n",
    "    for s in batch:\n",
    "        first_eos = np.where(np.array(s) == eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            res.append(\n",
    "                \"\".join(lookup_words(s[: first_eos[0]], vocab=vocab))\n",
    "                .replace(\"~\", \"\")\n",
    "                .strip()\n",
    "            )\n",
    "        else:\n",
    "            res.append(\n",
    "                \"\".join(lookup_words(s[:], vocab=vocab)).replace(\"~\", \"\").strip()\n",
    "            )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "\n",
    "def greedy_decode_batch(\n",
    "    model, src, src_mask, src_lengths, max_len=MAX_LEN, sos_index=1, eos_index=None\n",
    "):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "    batch_size = src.size(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(batch_size, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output, hidden = [], None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "                encoder_hidden, encoder_final, src_mask, prev_y, trg_mask, hidden\n",
    "            )\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data\n",
    "        output.append(next_word.cpu().numpy())\n",
    "        prev_y = next_word.unsqueeze(dim=1)\n",
    "\n",
    "    output = np.array(output)\n",
    "    output = np.stack(output).T\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict(\n",
    "    example_iter,\n",
    "    model,\n",
    "    max_len=MAX_LEN,\n",
    "    src_vocab=None,\n",
    "    trg_vocab=None,\n",
    "    num_batches=100,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    preds, sources, targets = [], [], []\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(example_iter):\n",
    "\n",
    "            source_batch = translate_batch(batch, vocab=SOURCE.vocab, target=False)\n",
    "            target_batch = translate_batch(batch, vocab=TARGET.vocab, target=True)\n",
    "\n",
    "            sources.extend(source_batch)\n",
    "            targets.extend(target_batch)\n",
    "\n",
    "            output = greedy_decode_batch(\n",
    "                model,\n",
    "                batch.src,\n",
    "                batch.src_mask,\n",
    "                batch.src_lengths,\n",
    "                max_len=max_len,\n",
    "                sos_index=trg_sos_index,\n",
    "                eos_index=trg_eos_index,\n",
    "            )\n",
    "\n",
    "            if trg_eos_index is not None:\n",
    "                for pred in output:\n",
    "                    if type(pred) == list:\n",
    "                        pred = np.array(pred)\n",
    "                    first_eos = np.where(pred == trg_eos_index)[0]\n",
    "                    if len(first_eos) > 0:\n",
    "                        # produce sentences\n",
    "                        preds.append(\n",
    "                            \"\".join(lookup_words(pred[: first_eos[0]], vocab=trg_vocab))\n",
    "                        )\n",
    "                    else:\n",
    "                        preds.append(\"\".join(lookup_words(pred[:], vocab=trg_vocab)))\n",
    "            pbar.update(1)\n",
    "    return preds, sources, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(tr_loss, tr_ppl, val_loss, val_ppl):\n",
    "    res = {\n",
    "        \"Train Loss\": np.mean(tr_loss),\n",
    "        \"Train PPL\": np.mean(tr_ppl),\n",
    "        \"Validation Loss\": np.mean(val_loss),\n",
    "        \"Validation PPL\": np.mean(val_ppl)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def save_json(fname, obj):\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def save_results(all_predictions, all_targets, all_sources, model_path=encoder_decoder_model_path):\n",
    "    res = {\n",
    "        \"predictions\": all_predictions,\n",
    "        \"targets\": all_targets,\n",
    "        \"sources\": all_sources,\n",
    "    }\n",
    "\n",
    "    save_json(os.path.join(model_path, \"encoder_decoder_results.json\"), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, criterion, optim, source_vocab, target_vocab, num_epochs=10, print_every=500, model_path=encoder_decoder_model_path\n",
    "):\n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_perplexities, valid_perplexities = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch = epoch + 1\n",
    "        print(\"Epoch\", epoch)\n",
    "        print(\"Training the model\")\n",
    "        model.train()\n",
    "\n",
    "        train_perplexity, train_loss = run_epoch(\n",
    "            (rebatch(PAD_INDEX, b) for b in train_iter),\n",
    "            model,\n",
    "            SimpleLossCompute(model.generator, criterion, optim),\n",
    "            print_every=print_every,\n",
    "            num_batches=len(train_iter),\n",
    "        )\n",
    "\n",
    "        print(\"Train Loss: %f\" % train_loss)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print(\"Evaluating the model\")\n",
    "            # print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), model, n=3, src_vocab=source_vocab.vocab, trg_vocab=target_vocab.vocab)\n",
    "            dev_perplexity, dev_loss = run_epoch(\n",
    "                (rebatch(PAD_INDEX, b) for b in valid_iter_batch),\n",
    "                model,\n",
    "                SimpleLossCompute(model.generator, criterion, None),\n",
    "                num_batches=len(valid_iter_batch),\n",
    "            )\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_perplexities.append(train_perplexity)\n",
    "            valid_losses.append(dev_loss)\n",
    "            valid_perplexities.append(dev_perplexity)\n",
    "\n",
    "            print(\"*\" * 30)\n",
    "            print(\"Epoch metrics\\n\")\n",
    "            print(\"Validation perplexity: %3.f \\n\" % dev_perplexity)\n",
    "            print(\"Validation Loss: %3.f \" % dev_loss)\n",
    "\n",
    "            print(\"*\" * 30)\n",
    "\n",
    "            if epoch == num_epochs:\n",
    "                model_name = os.path.join(model_path, \"encoder_decoder_model.pt\")\n",
    "\n",
    "                print(\"Saving model %s\" % model_name)\n",
    "\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "\n",
    "                preds, sources, targets = predict(\n",
    "                    (rebatch(PAD_INDEX, x) for x in valid_iter_batch),\n",
    "                    model,\n",
    "                    max_len=MAX_LEN,\n",
    "                    src_vocab=source_vocab.vocab,\n",
    "                    trg_vocab=target_vocab.vocab,\n",
    "                    num_batches=len(valid_iter_batch),\n",
    "                )\n",
    "\n",
    "                save_results(preds, targets, sources)\n",
    "\n",
    "    return train_perplexities, valid_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_words(x, vocab=None):\n",
    "    if vocab is not None:\n",
    "        x = [vocab.itos[i] for i in x]\n",
    "    return [str(t) for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 256\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT_RATE = 0.25\n",
    "LEARNING_RATE = 2*1e-5\n",
    "\n",
    "model = make_model(\n",
    "    len(SOURCE.vocab),\n",
    "    len(TARGET.vocab),\n",
    "    emb_size=EMB_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15\n",
    "PRINT_EVERY = 20000\n",
    "\n",
    "train_perplexities, valid_perplexities = train(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    print_every=PRINT_EVERY,\n",
    "    criterion=criterion,\n",
    "    optim=optim,\n",
    "    source_vocab=SOURCE,\n",
    "    target_vocab=TARGET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.890741110764172,\n",
       " 1.4811114213728331,\n",
       " 1.3909569295283717,\n",
       " 1.3182854119263536,\n",
       " 1.2850568909004818,\n",
       " 1.2535985835721168,\n",
       " 1.2308219660135085,\n",
       " 1.2078453773353905,\n",
       " 1.1877415031559226,\n",
       " 1.1736294333979227,\n",
       " 1.160788853441537,\n",
       " 1.1484450470626477,\n",
       " 1.1384484172610505,\n",
       " 1.1279865213512126,\n",
       " 1.1190539476046744]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppls = {\n",
    "    \"train\": train_perplexities,\n",
    "    \"val\": valid_perplexities\n",
    "}\n",
    "\n",
    "\n",
    "save_json(\n",
    "    os.path.join(encoder_decoder_model_path, \"ppls.json\"), ppls\n",
    ")\n",
    "\n",
    "save_json(\n",
    "    os.path.join(encoder_decoder_model_path, \"source_vocab.json\"), SOURCE.vocab.stoi\n",
    ")\n",
    "\n",
    "save_json(\n",
    "    os.path.join(encoder_decoder_model_path, \"target_vocab.json\"), TARGET.vocab.stoi\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 2\n",
    "\n",
    "### Модель sequence-to-sequence на основе архитектуры трансформера\n",
    "https://github.com/CyberZHG/keras-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --quiet keras-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>cn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251876</th>\n",
       "      <td>338008</td>\n",
       "      <td>въ лото 6852 преставися княь 1рославъ алеэсанд...</td>\n",
       "      <td>въ лѣто 6852 преставися князь ярославъ алексан...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196760</th>\n",
       "      <td>272746</td>\n",
       "      <td>полмехб лисего хребтоваго длиною 2 аршъи ширин...</td>\n",
       "      <td>полмеха лисего хребтоваго длиною 2 аршъ ширино...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82414</th>\n",
       "      <td>116372</td>\n",
       "      <td>9тъ 2огч убо за г⊗ѣхи порабощеъи</td>\n",
       "      <td>отъ бога убо за грѣхи порабощени</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60381</th>\n",
       "      <td>84973</td>\n",
       "      <td>ис[оріи съиускіъ</td>\n",
       "      <td>исторіи скифскія</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182205</th>\n",
       "      <td>255556</td>\n",
       "      <td>2пэаыкарубковыешитсолотоми</td>\n",
       "      <td>2 платка рубковые шиты золотомъ</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                src  \\\n",
       "251876  338008  въ лото 6852 преставися княь 1рославъ алеэсанд...   \n",
       "196760  272746  полмехб лисего хребтоваго длиною 2 аршъи ширин...   \n",
       "82414   116372                   9тъ 2огч убо за г⊗ѣхи порабощеъи   \n",
       "60381    84973                                   ис[оріи съиускіъ   \n",
       "182205  255556                         2пэаыкарубковыешитсолотоми   \n",
       "\n",
       "                                                      trg  cn  \n",
       "251876  въ лѣто 6852 преставися князь ярославъ алексан...  60  \n",
       "196760  полмеха лисего хребтоваго длиною 2 аршъ ширино...  76  \n",
       "82414                    отъ бога убо за грѣхи порабощени  32  \n",
       "60381                                    исторіи скифскія  16  \n",
       "182205                    2 платка рубковые шиты золотомъ  26  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "transformer_model_path = \"transformer_model\"\n",
    "if not os.path.exists(transformer_model_path):\n",
    "    os.makedirs(transformer_model_path)\n",
    "\n",
    "\n",
    "strata = df[\"cn\"].values\n",
    "train_df, test_df = train_test_split(df, stratify=strata, train_size=0.9, shuffle=True)\n",
    "\n",
    "\n",
    "train_df.to_csv(os.path.join(transformer_model_path, \"train.tsv\"), sep=\"\\t\", index=False)\n",
    "test_df.to_csv(os.path.join(transformer_model_path, \"test.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_token_dict(text_list):\n",
    "    token_dict = {\n",
    "        '<PAD>': 0,\n",
    "        '<START>': 1,\n",
    "        '<END>': 2,\n",
    "    }\n",
    "    for text in tqdm(text_list, total=len(text_list)):\n",
    "        for token in text:\n",
    "            if token not in token_dict:\n",
    "                token_dict[token] = len(token_dict)\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "def prepare_data(df, source_token_dict, target_token_dict):\n",
    "    df[\"src_tok\"] = df[\"src\"].apply(tokenize)\n",
    "    df[\"trg_tok\"] = df[\"trg\"].apply(tokenize)\n",
    "\n",
    "    source_tokens = df[\"src_tok\"].tolist()\n",
    "    target_tokens = df[\"trg_tok\"].tolist()\n",
    "\n",
    "    encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
    "    decode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
    "    output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
    "    \n",
    "    source_max_len = max(map(len, encode_tokens))\n",
    "    target_max_len = max(map(len, decode_tokens))\n",
    "    \n",
    "    encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
    "    decode_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decode_tokens]\n",
    "    output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
    "    \n",
    "    encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
    "    decode_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decode_tokens]\n",
    "    decode_output = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n",
    "    \n",
    "    return encode_input, decode_input, decode_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_source_token_dict = build_token_dict(train_df.src.tolist())\n",
    "tr_target_token_dict = build_token_dict(train_df.trg.tolist())\n",
    "\n",
    "tr_target_token_dict_inv = {v: k for k, v in tr_target_token_dict.items()}\n",
    "tr_source_token_dict_inv = {v: k for k, v in tr_source_token_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(\n",
    "    os.path.join(transformer_model_path, \"source_token_dict.json\"), tr_source_token_dict\n",
    ")\n",
    "\n",
    "save_json(\n",
    "    os.path.join(transformer_model_path, \"target_token_dict.json\"), tr_target_token_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras_transformer import get_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "EMBED_DIM = 512\n",
    "HIDDEN_DIM = 256\n",
    "HEAD_NUM = 4\n",
    "ENC_NUM = 3\n",
    "DEC_NUM = 3\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.00001\n",
    "\n",
    "\n",
    "model = get_model(\n",
    "    token_num=max(len(tr_source_token_dict), len(tr_target_token_dict)),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    encoder_num=ENC_NUM,\n",
    "    decoder_num=DEC_NUM,\n",
    "    head_num=HEAD_NUM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    use_same_embed=False,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=LEARNING_RATE), loss='sparse_categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9170/9170 - 477s - loss: 1.1074\n",
      "Epoch 2/15\n",
      "9170/9170 - 477s - loss: 0.6864\n",
      "Epoch 3/15\n",
      "9170/9170 - 477s - loss: 0.3320\n",
      "Epoch 4/15\n",
      "9170/9170 - 477s - loss: 0.2509\n",
      "Epoch 5/15\n",
      "9170/9170 - 477s - loss: 0.2169\n",
      "Epoch 6/15\n",
      "9170/9170 - 477s - loss: 0.1975\n",
      "Epoch 7/15\n",
      "9170/9170 - 477s - loss: 0.1849\n",
      "Epoch 8/15\n",
      "9170/9170 - 478s - loss: 0.1752\n",
      "Epoch 9/15\n",
      "9170/9170 - 478s - loss: 0.1674\n",
      "Epoch 10/15\n",
      "9170/9170 - 478s - loss: 0.1609\n",
      "Epoch 11/15\n",
      "9170/9170 - 478s - loss: 0.1553\n",
      "Epoch 12/15\n",
      "9170/9170 - 479s - loss: 0.1503\n",
      "Epoch 13/15\n",
      "9170/9170 - 478s - loss: 0.1456\n",
      "Epoch 14/15\n",
      "9170/9170 - 478s - loss: 0.1415\n",
      "Epoch 15/15\n",
      "9170/9170 - 478s - loss: 0.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a95442a58>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH_NUM = 15\n",
    "\n",
    "\n",
    "encode_input, decode_input, decode_output = prepare_data(\n",
    "    train_df, tr_source_token_dict, tr_target_token_dict\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=[np.array(encode_input), np.array(decode_input)],\n",
    "    y=np.array(decode_output),\n",
    "    epochs=EPOCH_NUM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(transformer_model_path, \"transformer_model_base.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка моделей на внутренней тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --quiet editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred, print_num=50):\n",
    "    numCharErr = 0\n",
    "    numCharTotal = 0\n",
    "    numStringOK = 0\n",
    "    numStringTotal = 0\n",
    "    counter = 0\n",
    "\n",
    "    word_eds, word_true_lens = [], []\n",
    "    \n",
    "    for i, pred in enumerate(y_pred):\n",
    "        true = y_true[i]\n",
    "        \n",
    "        numStringOK += 1 if true == pred else 0\n",
    "        \n",
    "        numStringTotal += 1\n",
    "        dist = editdistance.eval(pred, true)\n",
    "        \n",
    "        numCharErr += dist\n",
    "        numCharTotal += len(true)\n",
    "        \n",
    "        pred_words = pred.split()\n",
    "        true_words = true.split()\n",
    "        word_eds.append(editdistance.eval(pred_words, true_words))\n",
    "        word_true_lens.append(len(true_words))\n",
    "        \n",
    "        is_print = np.random.choice([True, False], p=[0.05, 0.95])\n",
    "        if is_print and counter < print_num and len(true) > 15:\n",
    "            print('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + true + '\"', '->', '\"' + pred + '\"')\n",
    "            counter += 1\n",
    "\n",
    "    charErrorRate = numCharErr / numCharTotal\n",
    "    wordErrorRate = sum(word_eds) / sum(word_true_lens) \n",
    "    stringAccuracy = numStringOK / numStringTotal\n",
    "    print(\n",
    "        'Character error rate: %f%%. Word error rate: %f%%. String accuracy: %f%%.' % \\\n",
    "        (charErrorRate*100.0,wordErrorRate*100.0, stringAccuracy*100.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer(object):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.src_stoi = self.config[\"vocab\"][\"src_stoi\"]\n",
    "        self.trg_stoi = self.config[\"vocab\"][\"trg_stoi\"]\n",
    "        self.src_itos = {v: k for k, v in self.src_stoi.items()}\n",
    "        self.trg_itos = {v: k for k, v in self.trg_stoi.items()}\n",
    "        self.eos_token = self.config[\"tok\"][\"eos_token\"]\n",
    "        self.unk_token = self.config[\"tok\"][\"unk_token\"]\n",
    "        self.pad_token = self.config[\"tok\"][\"pad_token\"]\n",
    "        self.sos_token = self.config[\"tok\"][\"sos_token\"]\n",
    "    \n",
    "    def encode(self, sequence):\n",
    "        enc = [self.src_stoi[char] if char in self.src_stoi else self.stoi[self.unk_token_id] for char in list(sequence)] + [self.src_stoi[self.eos_token]]\n",
    "        return torch.tensor(enc).unsqueeze(0)\n",
    "    \n",
    "    def create_mask(self, enc):\n",
    "        return (enc != self.src_stoi[self.pad_token]).unsqueeze(-2)\n",
    "    \n",
    "    def get_length(self, enc):\n",
    "        return torch.tensor(enc.shape[-1], dtype=torch.int64).unsqueeze(0)\n",
    "\n",
    "\n",
    "def load_model(config, device):\n",
    "\n",
    "    model_params = config[\"model\"]\n",
    "    model_path = model_params[\"model_path\"]\n",
    "    emb_size = model_params[\"emb_size\"]\n",
    "    hidden_size = model_params[\"hidden_size\"]\n",
    "    num_layers = model_params[\"num_layers\"]\n",
    "    dropout = model_params[\"dropout\"]\n",
    "\n",
    "    state_dict = torch.load(model_path)\n",
    "    source_dim = state_dict[\"src_embed.weight\"].shape[0]\n",
    "    target_dim = state_dict[\"trg_embed.weight\"].shape[0]\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(emb_size, hidden_size, BahdanauAttention(hidden_size), num_layers=num_layers, dropout=dropout),\n",
    "        nn.Embedding(source_dim, emb_size),\n",
    "        nn.Embedding(target_dim, emb_size),\n",
    "        Generator(hidden_size, target_dim)\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_json(fname_path):\n",
    "    with open(fname_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_config(encoder_decoder_model_path,\n",
    "                 model_name=\"encoder_decoder_model.pt\",\n",
    "                 emb_size=256,\n",
    "                 hidden_size=512,\n",
    "                 num_layers=2,\n",
    "                 dropout_rate=0.2,\n",
    "                 source_vocab=\"source_vocab.json\",\n",
    "                 target_vocab=\"target_vocab.json\"\n",
    "                ):\n",
    "    config = {\n",
    "        \"model\": {\n",
    "            \"model_path\": os.path.join(encoder_decoder_model_path, model_name),\n",
    "            \"emb_size\": emb_size,\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout_rate\n",
    "        },\n",
    "        \"tok\": {\n",
    "            \"pad_token\": PAD_TOKEN,\n",
    "            \"sos_token\": SOS_TOKEN,\n",
    "            \"eos_token\": EOS_TOKEN,\n",
    "            \"unk_token\": UNK_TOKEN\n",
    "        },\n",
    "        \"vocab\": {\n",
    "            \"src_stoi\": load_json(\n",
    "                os.path.join(encoder_decoder_model_path, source_vocab)\n",
    "            ),\n",
    "            \"trg_stoi\": load_json(\n",
    "                os.path.join(encoder_decoder_model_path, target_vocab)\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_copy(sequence, output):\n",
    "    diff = len(sequence) - len(output)\n",
    "    if diff > 0:\n",
    "        return output + sequence[-diff:]\n",
    "    return output\n",
    "\n",
    "\n",
    "def greedy_decode(sequence, model, tokenizer, device, copy=False, max_len=256):\n",
    "    src = tokenizer.encode(sequence).to(device)\n",
    "    src_mask = tokenizer.create_mask(src).to(device)\n",
    "    src_length = tokenizer.get_length(src).to(device)\n",
    "    sos_index = tokenizer.trg_stoi[tokenizer.sos_token]\n",
    "    eos_index = tokenizer.trg_stoi[tokenizer.eos_token]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_length)\n",
    "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "              encoder_hidden, encoder_final, src_mask,\n",
    "              prev_y, trg_mask, hidden)\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data.item()\n",
    "        output.append(next_word)\n",
    "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
    "    \n",
    "    output = np.array(output)\n",
    "    if eos_index is not None:\n",
    "        first_eos = np.where(output==eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            output = output[:first_eos[0]]      \n",
    "    \n",
    "    output = \"\".join([tokenizer.trg_itos[token_id] for token_id in output.tolist()])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "encoder_decoder_model_config = build_config(encoder_decoder_model_path=encoder_decoder_model_path)\n",
    "tokenizer = CharTokenizer(config=encoder_decoder_model_config)\n",
    "encoder_decoder_model = load_model(config=encoder_decoder_model_config, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "encoder_decoder_result_path = os.path.join(encoder_decoder_model_path, \"encoder_decoder_results.json\")\n",
    "encoder_decoder_result = load_json(encoder_decoder_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder_prediction = encoder_decoder_result[\"predictions\"]\n",
    "encoder_decoder_trgs = encoder_decoder_result[\"targets\"]\n",
    "encoder_decoder_srcs = encoder_decoder_result[\"sources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример генерации на аугментированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'потомй жх воздгилнуша церков съ ткапезою др1вяну во имя святыхъ ве8имихн гучедикъ 40 иже въ севаттіи'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_srcs[-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'потомъ же воздвилнуша церковь съ трапезою древяну во имя святыхъ великихъ гученикъ 40 иже въ севастіи'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_prediction[-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'потомъ же воздвигнуша церковь съ трапезою древяну во имя святыхъ великихъ мученикъ 40 иже въ севастіи'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_trgs[-50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:6] \"марта въ 31 день\" -> \"ма1тавъ3ыден\"\n",
      "[ERR:6] \"ничто же бо имѣю\" -> \"вичтожебосмѣт\"\n",
      "[ERR:4] \"такъ   отскочили\" -> \"такъотскодили\"\n",
      "[ERR:2] \"1 чаршка яшмовая\" -> \"1чаршкаяшмовая\"\n",
      "[ERR:5] \"сигъ подо зваромъ\" -> \"сиъьпошоваромъ\"\n",
      "[ERR:3] \"пирогъ росольной\" -> \"пиобгъ росолной\"\n",
      "[ERR:3] \"марта въ 21 день\" -> \"марта вл 21 ьен\"\n",
      "[ERR:3] \"трошке васильеву\" -> \"трршкевасил4еву\"\n",
      "[ERR:2] \"иванъ вельяминовъ\" -> \"иванъвеляминовъ\"\n",
      "[ERR:6] \"2 бочки полуперцу\" -> \"2бопкиколуйенцу\"\n",
      "[ERR:6] \"степанку лазареву\" -> \"стъцансулафреву\"\n",
      "[ERR:4] \"7102го  въ 26 день\" -> \"7102говг 26 ден\"\n",
      "[ERR:5] \"иду жъ я въ дорогу\" -> \"идужъзвъ дор0гу\"\n",
      "[ERR:2] \"пирогъ колобобой\" -> \"пирогъ щплобобой\"\n",
      "[ERR:4] \"апрѣля въ 7 день\" -> \"ам]ѣл7 въ 7 д⊗нь\"\n",
      "[ERR:3] \"петръ сандетцкой\" -> \"петръ жандетцсог\"\n",
      "[OK] \"игоне офонасьеву\" -> \"игоне офонасьеву\"\n",
      "[ERR:3] \"поѣхали на войну\" -> \"поѣхала н2 войнч\"\n",
      "[ERR:4] \"исторіи скифскія\" -> \"ис[оріи съиускіъ\"\n",
      "[ERR:3] \"степану щоголеву\" -> \"йтепуну щоголе2у\"\n",
      "[ERR:4] \"гуляй золотаревъ\" -> \"гуляй д5 оѣаревъ\"\n",
      "[ERR:4] \"марта въ 11 день\" -> \"марта 6ъ в1 ш+нь\"\n",
      "[ERR:4] \"сѣрому кушнереву\" -> \"сѣрн6у кушне…еьу\"\n",
      "[ERR:3] \"волость коурдакъ\" -> \"втлоъть кйурдакъ\"\n",
      "[ERR:4] \"тѣло окрашиваное\" -> \"1ѣло ⊕крашиван74\"\n",
      "[ERR:4] \"купчая на юрьино\" -> \"⊗у+чая на юрь…ло\"\n",
      "[ERR:1] \"иванку булгакову\" -> \"иванку 1улгакову\"\n",
      "[ERR:1] \"припись у отписи\" -> \"приписъ у отписи\"\n",
      "[ERR:4] \"по 100 четвертей\" -> \"пы 100 5етіьртей\"\n",
      "[OK] \"филипку данилову\" -> \"филипку данилову\"\n",
      "[OK] \"о борисъ же царѣ\" -> \"о борисъ же царѣ\"\n",
      "[ERR:3] \"марта въ 31 день\" -> \"март… 5ъ 31 ден⊗\"\n",
      "[ERR:3] \"третьякъ копнинъ\" -> \"тбетякъ копнинъб\"\n",
      "[ERR:3] \"тренке зиновьеву\" -> \"треные зи5овьевж\"\n",
      "[ERR:3] \"волость коурдакъ\" -> \"в8шосдь коурдакъ\"\n",
      "[ERR:4] \"ивашку чувардину\" -> \"ивашкi чуваедигг\"\n",
      "[ERR:4] \"тѣло окрашиваное\" -> \"ть0л окраш…ваное\"\n",
      "[ERR:5] \"зри гонецъ гонитъ\" -> \"григонееъгонитъф\"\n",
      "[ERR:3] \"въ болшой ризницѣ\" -> \"в0 болшой рлницѣ\"\n",
      "[ERR:4] \"февраля въ 3 день\" -> \"феврал1 въ 3дпнч\"\n",
      "[ERR:3] \"апрѣля въ 13 день\" -> \"аорѣля въ 13 дан\"\n",
      "[ERR:4] \"о приходѣ боярина\" -> \"оприходѣ гоаринй\"\n",
      "[ERR:3] \"о бою подъ торжкомъ\" -> \"обоюподъторжкомъ\"\n",
      "[ERR:4] \"2го дѣйства сенъ 7я\" -> \"2годѣйствасднъ7я\"\n",
      "[ERR:5] \"а юрьи иде къ суздалю\" -> \"аюрьиидекъсудалю\"\n",
      "[ERR:4] \"истомке потулову\" -> \"цдтомке мотуловуэ\"\n",
      "[ERR:4] \"деревни похомьева\" -> \"дхрквни 3охомьква\"\n",
      "[OK] \"6й станицѣ 2 челъ\" -> \"6й станицѣ 2 челъ\"\n",
      "[ERR:4] \"арзамазской уѣздъ\" -> \"адзамаз+фой уѣздт\"\n",
      "[ERR:3] \"октября въ 1 день\" -> \"октябрм въ   чень\"\n",
      "Character error rate: 15.451051%. Word error rate: 62.765559%. String accuracy: 3.867861%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=encoder_decoder_trgs,\n",
    "    y_pred=encoder_decoder_srcs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевые значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] \"ноября въ 22 день\" -> \"ноября въ 22 день\"\n",
      "[OK] \"декабря въ 1 день\" -> \"декабря въ 1 день\"\n",
      "[ERR:7] \"и збыся во время се\" -> \"и бысть возвресяся\"\n",
      "[OK] \"марта въ 31 день\" -> \"марта въ 31 день\"\n",
      "[OK] \"олешке кричалеву\" -> \"олешке кричалеву\"\n",
      "[OK] \"ондрей подлесовъ\" -> \"ондрей подлесовъ\"\n",
      "[OK] \"7102го  въ 26 день\" -> \"7102го  въ 26 день\"\n",
      "[OK] \"сентября въ 20 день\" -> \"сентября въ 20 день\"\n",
      "[OK] \"сентября въ 19 день\" -> \"сентября въ 19 день\"\n",
      "[ERR:1] \"4440 четъ ячмени\" -> \"4440 четъ тячмени\"\n",
      "[ERR:2] \"пятой григорьевъ\" -> \"пятка григорьевъ\"\n",
      "[ERR:2] \"тѣ  тамъ погибли\" -> \"тѣ  таты погибли\"\n",
      "[OK] \"богданъ поздеевъ\" -> \"богданъ поздеевъ\"\n",
      "[OK] \"лучѣ бы повѣсить\" -> \"лучѣ бы повѣсить\"\n",
      "[OK] \"беляйку федорову\" -> \"беляйку федорову\"\n",
      "[OK] \"марта въ 31 день\" -> \"марта въ 31 день\"\n",
      "[ERR:1] \"бабарике фролову\" -> \"бадарике фролову\"\n",
      "[OK] \"тренке зиновьеву\" -> \"тренке зиновьеву\"\n",
      "[OK] \"о измѣнѣ донской\" -> \"о измѣнѣ донской\"\n",
      "[ERR:4] \"у другого столпа\" -> \"у лучного столпа\"\n",
      "[ERR:1] \"первуше обрамову\" -> \"первуше обрадову\"\n",
      "[OK] \"5500 пудъ свинцу\" -> \"5500 пудъ свинцу\"\n",
      "[ERR:2] \"ларя сыромятникъ\" -> \"ларя жеромятникъ\"\n",
      "[OK] \"ивашку игнатьеву\" -> \"ивашку игнатьеву\"\n",
      "[ERR:1] \"павлику захарову\" -> \"павлику захирову\"\n",
      "[OK] \"ермошке давыдову\" -> \"ермошке давыдову\"\n",
      "[OK] \"марта въ 24 день\" -> \"марта въ 24 день\"\n",
      "[OK] \"глава  панкратія\" -> \"глава  панкратія\"\n",
      "[ERR:1] \"добрыня семеновъ\" -> \"добрыня семенову\"\n",
      "[OK] \"марта въ 25 день\" -> \"марта въ 25 день\"\n",
      "[OK] \"тимошке оникееву\" -> \"тимошке оникееву\"\n",
      "[OK] \"миките замятнину\" -> \"миките замятнину\"\n",
      "[OK] \"терешке давыдову\" -> \"терешке давыдову\"\n",
      "[OK] \"первуше васильеву\" -> \"первуше васильеву\"\n",
      "[ERR:1] \"зри гонецъ гонитъ\" -> \"зри вонецъ гонитъ\"\n",
      "[OK] \"ортемку кушнереву\" -> \"ортемку кушнереву\"\n",
      "[OK] \"25 черевъ рысьихъ\" -> \"25 черевъ рысьихъ\"\n",
      "[ERR:2] \"максиму савенкову\" -> \"максиму матенкову\"\n",
      "[OK] \"потапку григорьеву\" -> \"потапку григорьеву\"\n",
      "[ERR:5] \"3 султанъ турецкій\" -> \"осалтынъ тулецкій\"\n",
      "[ERR:2] \"остала бо есми царя\" -> \"остала бе сми царя\"\n",
      "[ERR:4] \"въ варску … пробѣлъ\" -> \"поварску … пробѣло\"\n",
      "[OK] \"се же рече грозя имъ\" -> \"се же рече грозя имъ\"\n",
      "[OK] \"164 ноября въ 14 день\" -> \"164 ноября въ 14 день\"\n",
      "[OK] \"въ болшой ризницѣ\" -> \"въ болшой ризницѣ\"\n",
      "[ERR:1] \"недоброму павлову\" -> \"недоброму панлову\"\n",
      "[ERR:5] \"въ книги записано\" -> \"въ кожди выписано\"\n",
      "[OK] \"припись стряпчимъ\" -> \"припись стряпчимъ\"\n",
      "[OK] \"ивашку полосухину\" -> \"ивашку полосухину\"\n",
      "[ERR:2] \"степанку данилову\" -> \"степанку ланинову\"\n",
      "Character error rate: 5.099224%. Word error rate: 17.158393%. String accuracy: 39.776701%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=encoder_decoder_trgs,\n",
    "    y_pred=encoder_decoder_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "te_encode_input, te_decode_input, te_decode_output = prepare_data(\n",
    "    test_df, tr_source_token_dict, tr_target_token_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_transformer import decode\n",
    "\n",
    "\n",
    "def transformer_decode(decode_input, vocab=tr_target_token_dict_inv):\n",
    "    decode_input = [x for x in decode_input if not vocab[x] in (\"<PAD>\", \"<END>\", \"<START>\")]\n",
    "    return \"\".join(map(lambda x: vocab[x], decode_input))\n",
    "\n",
    "\n",
    "decoded = decode(\n",
    "    model,\n",
    "    te_encode_input,\n",
    "    start_token=tr_target_token_dict['<START>'],\n",
    "    end_token=tr_target_token_dict['<END>'],\n",
    "    pad_token=tr_target_token_dict['<PAD>'],\n",
    "    temperature=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['богь отець богь сынь правда истинна милосердіе мирь',\n",
       " 'куплены въ полату въ казенную на дверь',\n",
       " 'у подлинной памяти припись діака григорья нечаева справка подьячево юрья собакина',\n",
       " 'у главы жъ 2 жемчюга да 2 яхонты въ гнѣздехъ',\n",
       " 'на оборотѣ столникъ донской']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformer_test_true = [transformer_decode(x) for x in te_decode_input]\n",
    "y_transformer_test_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['того ототь бого сынь правда истанна миласердіе синь',\n",
       " 'куплены въ солату въ казеннуюнцоверь',\n",
       " 'у подлинной памяти припись діака григоря нечаева справка подьячевою рясобакина',\n",
       " 'у главе жъ и жежзюга да и яхостыхъ гнѣздехъ',\n",
       " 'на оборотѣ похлоикъ понакой']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformer_test_pred = [transformer_decode(x) for x in decoded]\n",
    "y_transformer_test_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:11] \"но изгубилъ многое воинство отыде со срамомъ многимъ\" -> \"но итгубилъ хногоу во]нстщо отцде 8о срамоьс внокимъ\"\n",
      "[ERR:8] \"подать емельяну игнатевичю украинцову\" -> \"податг имесьюнуигнатемичю украингооу\"\n",
      "[ERR:7] \"стольники были на службѣ безъсъезду\" -> \"стольни6и э5ли 7а слу]бѣ жезъс езду\"\n",
      "[ERR:9] \"а по осмотру въ томъ сундукѣ бѣлаго платя\" -> \"6 по осмутру вч тцмъ …у0дукѣ бѣла0о шлакя\"\n",
      "[ERR:11] \"на оборотѣ  172 октября въ 16 д подалъ бобыль гаврилка\" -> \"на обо2оиѣ  172 оi3ябдя въ 10 н подалъ бо5ыль гжвѣилк…\"\n",
      "[OK] \"а у подлинной грамоты назади пишетъ\" -> \"а у подлинной грамоты назади пишетъ\"\n",
      "[ERR:13] \"потребно ю съясти изрядно разрѣзавши на мелкія части\" -> \"2нткефнф ю сьязти 1⊗р1дно разрѣзавшина меніія части\"\n",
      "[OK] \"и сведши турки три брани съ волохи на нихъ же всюду поражаеми бяху\" -> \"и сведши турки три брани съ волохи на нихъ же всюду поражаеми бяху\"\n",
      "[ERR:1] \"богъ же по   и исцелиль ихъ\" -> \"богъ же по   и исцелил ихъ\"\n",
      "[ERR:13] \"и были въ войскѣ запорожскомъ у гетмана у богдана хмелницкого\" -> \"и быми въ войекд запорофс8омъ у гетйана у ъовдаща хмещнтякогок\"\n",
      "[ERR:7] \"василей петровъ сынъ зиновьевъ\" -> \"василрй пьтровб сын5 ѣинов…е…ъ\"\n",
      "[ERR:5] \"князь ондрей ситцкой\" -> \"зояуь ондпей сптцкой\"\n",
      "[ERR:9] \"платокъ по концамъ заткана золотомъ съ шолкомъ\" -> \"пл5тока по концамъ зашдава зоiот7мъ сн ыолкомъ\"\n",
      "[ERR:6] \"и поклоняся до земли\" -> \"и поксгняпя до оцли\"\n",
      "[ERR:6] \"лѣто бо бе то сухо жита посохли\" -> \"лѣѣо шо бе то сухо жпт  2о[охли\"\n",
      "[ERR:1] \"по склейкамъ  145го  въ 27 день государь пожаловалъ есаула ивана поленова …\" -> \"по склейкамъ  145го  въ 27 день государ пожаловалъ есаула ивана поленова …\"\n",
      "[ERR:3] \"звено осетрины ступишные\" -> \"звлно осетрины съупишныъ\"\n",
      "[ERR:12] \"а зарядъ въ записехъ написали по дватцети рублевъ\" -> \"аарядж въаписехд нуяисали порвфтцетирублевъ\"\n",
      "[ERR:6] \"иванъ григорьевъ сынъ мячковъ\" -> \"иванъ 6риг7юьевъ сын⊗ 9ячновъ\"\n",
      "[ERR:10] \"куплены къ церковному строенію на срачицы\" -> \"к8плены къ церкоауому ятреуній на 4бачццы\"\n",
      "[ERR:5] \"и пріѣхали на одинъ белвардъ которой называется поста  де  италія\" -> \"и пріѣйали на одинъ белвакдъ которой называется восжа  де  итамія\"\n",
      "[ERR:10] \"сѣдло ветхая подушка и крилци сафіанніе красніе\" -> \"сѣдл⊗ ветха7 поттшка т крил⊗и саф⊕ан ье краеніе\"\n",
      "[ERR:6] \"а  боярыни въ скамьѣ сидѣли\" -> \"а  бобрз6и віскамьѣ сидѣлр\"\n",
      "[ERR:13] \"у подписи на государевы грамоты припись дьяка  комсина\" -> \"у пофпи6и са досъдаревы гр…моры4рифбсь дьякй  ко6сина\"\n",
      "[ERR:9] \"въ переславль  резанской къ василью чевкину\" -> \"в0 переславлд  резбнсжо9 к7 васильь чевсиэу\"\n",
      "[ERR:6] \"иванъ ондреевъ сынъ годуновъ\" -> \"рвднъ онд9]евъ сынъ годьновж\"\n",
      "[ERR:1] \"князь иванъ княжь ондреевъ сынъ дашковъ\" -> \"княь иванъ княжь ондреевъ сынъ дашковъ\"\n",
      "[ERR:1] \"писана на москвѣ  7122го  въ 12 день\" -> \"писана на москвѣ  7122го  въ 12 ден\"\n",
      "[ERR:3] \"у того столпа отправляли  литію\" -> \"у того 1толпа отпревияли  литію\"\n",
      "[ERR:7] \"и оттоль выняли его и отвезли на котелъ и сожгли въ аду которой адъ онъ зделалъ себѣ на потѣху\" -> \"и оттол выняфи его и отвели 2а котелъ и сожгли вс аду которой аеъ онъ делалъ себѣ на потѣху\"\n",
      "[ERR:5] \"а на ризахъ и на стихоряхъ оплечья и креста и звѣзды и омету нѣтъ\" -> \"а на риахе и на етихоряхъ кплечя и креста и звѣзды и омету нѣтъ\"\n",
      "[ERR:12] \"писанъ на колмогорахъ въ дому нашемъ  7199 мая въ 25 день\" -> \"п5саръ на аолмогшжахъ въ дофу юашямъ т 7199 мая въ у5 дбн\"\n",
      "[ERR:3] \"сентября въ 18 день\" -> \"сентября въ 1ю дюн\"\n",
      "[ERR:1] \"въ той остари стоялъ я іюня въ 27 день до ночи\" -> \"въ той остари стоялъ я іюня въ 27 ден до ночи\"\n",
      "[ERR:5] \"да рискіе соли 400 бочекъ\" -> \"да я]скіе соли 400 бсчябъ\"\n",
      "[ERR:1] \"кубокъ зъ кровлею на кровлѣ 3 королка зъ лица и въ серединѣ золоченъ сплошъ вѣсу въ нем полфунта\" -> \"кубокъ зъ кровлею на кровлѣ 3 королка ъ лица и въ серединѣ золоченъ сплошъ вѣсу въ нем полфунта\"\n",
      "[ERR:5] \"155го іюля въ 3 день\" -> \"155гоіюлявъ3деня\"\n",
      "[ERR:9] \"5 суконъ лазуровыхъ полавочныхъ а въ ныхъ 21 аршинъ\" -> \"5суконълауровыхъполавочныхъавъныхъ21аршинъ\"\n",
      "[ERR:1] \"о отшествіи отъ отца и матери\" -> \"о отшествіи отъ отци и матери\"\n",
      "[ERR:9] \"голунцу 22 аршина съ полуаршиномъ\" -> \"гоцуйцу22арш6н3съполуажшиномъ\"\n",
      "[ERR:1] \"абіе абіе исполнитца\" -> \"абіе абіеисполнитца\"\n",
      "[ERR:10] \"всего сто дватцать одинъ рубль дватцать пять алтынъ\" -> \"все3о сло дваэцать о5инр р4бль дватцат1 пзтб нлтынъ\"\n",
      "[ERR:7] \"подвязывалъ лѣса въ казенной полате\" -> \"поцвнзывалъ фѣсквъказеннод полате\"\n",
      "[ERR:4] \"и ко кресту максимъ сунбуловъ приведенъ того жъ числа\" -> \"и ко креслу максимъ лунбтловъ приведенъ того жъ чисэа\"\n",
      "[ERR:2] \"ахметъ  князя сулешова гонецъ тукашъ государю челомъ ударилъ отъ себя лукъ\" -> \"ахметъ  князя сулешова го6ецъ тукашъ государю чбломъ ударилъ отъ себя лукъ\"\n",
      "[ERR:11] \"писанъ на москвѣ  7109го октября въ 24 день\" -> \"писанъ нн мосывѣ р ч109ьо 0йтяотя вм 24 ден\"\n",
      "[ERR:3] \"справилъ подьячей иванко дедковъ\" -> \"справилъподьячейиванкодедковъ\"\n",
      "[ERR:4] \"у нестера сынъ родіонъ\" -> \"унесте6асынъродіонъ\"\n",
      "[ERR:7] \"простыня застѣнокъ шитъ шолкомъ\" -> \"гз6стжня засэѣнокъ шитъ оолкомс\"\n",
      "[ERR:8] \"подъ тою тюрмою ниско въ землѣ  другая тюрма\" -> \"по4ъ [ою тюрмою нфско гъ й[млѣ  дрцгая тюрмх\"\n",
      "Character error rate: 15.433565%. Word error rate: 62.671590%. String accuracy: 3.794129%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=y_transformer_test_true,\n",
    "    y_pred=test_df[\"src\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевые значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:9] \"о войнѣ на греки како посылалъ велики князь ярославъ сына своего воевати царьградъ\" -> \"о вридѣ за греки како посылалъ велики кназь ярославъ сына своего воечаты цареградѣ\"\n",
      "[ERR:5] \"а переславское драгунское и салдатцкое  устроить въ переславле  резанскомъ\" -> \"а переславское драгу нское и салдатцкое устроить въ переславле реренскомъ\"\n",
      "[ERR:8] \"двѣ пари ножей съ вилки съ серебреною оправою\" -> \"двѣ парино жей съ вилки съ серебрея обрававою\"\n",
      "[ERR:8] \"по той дорогѣ много горъ по которымъ растутъ мелкіе лѣса\" -> \"по все дорскѣ много годъ по потерымъ растутъ мелкіе лѣса\"\n",
      "[ERR:2] \"князь петръ канъмурзинъ сынъ урусовъ\" -> \"князь петръ канъ муринъ сынъ урусовъ\"\n",
      "[ERR:7] \"и черкасы тотчасъ пошли съ ними подъ астрахань\" -> \"2 черка сытотча съ пошлитъ ними полъ астрахань\"\n",
      "[ERR:4] \"деисусъ 7 образовъ писанъ на стѣнѣ на золотѣ\" -> \"черсусъ 7 отразовъ писанъ на стѣнѣ на молотѣ\"\n",
      "[ERR:4] \"буди же по глаголу вашему\" -> \"буди же поглаго оувашему\"\n",
      "[ERR:12] \"пускай ево испекли  хлѣбъ сладокъ святѣй троицѣ\" -> \"пускай въ о ценькои  хрѣбъ сладокъ сертѣй твоицѣ\"\n",
      "[ERR:3] \"кто вѣсть како чюдо намъ богъ имать послати\" -> \"кто вѣсть како чюдо намъ еотъ шмать послати\"\n",
      "[ERR:6] \"182 г октября въ 5 день тѣ деньги даны оптекарского двора подьячему любиму совѣтову\" -> \"по2 г октября въ 5 день тѣ деньги даны митекарского двора польячюму любиму совѣтову\"\n",
      "[OK] \"декабря въ 6 день\" -> \"декабря въ 6 день\"\n",
      "[ERR:7] \"а никиту рамановича грабилъ\" -> \"а ники еурази зановича грабилъ\"\n",
      "[ERR:3] \"икра зернистая черная\" -> \"и ра сернистая чезная\"\n",
      "[ERR:8] \"куплены къ церковному строенію на срачицы\" -> \"куплены къ церкову ому ятреуній на обачицы\"\n",
      "[ERR:2] \"ничто же бо имѣю\" -> \"мичто же бо мѣю\"\n",
      "[OK] \"въ мурамъ пріѣхали іюня въ 16 день\" -> \"въ мурамъ пріѣхали іюня въ 16 день\"\n",
      "[ERR:7] \"а  боярыни въ скамьѣ сидѣли\" -> \"а  бобрати воскамью сидѣлъ\"\n",
      "[ERR:13] \"у подписи на государевы грамоты припись дьяка  комсина\" -> \"у поспили са досъ даревы граморы присть дьякой  колсина\"\n",
      "[ERR:5] \"въ дмитровѣ гаврило петровъ сынъ островской\" -> \"въ двитроже гаврило петаовъ сылъ островской\"\n",
      "[ERR:6] \"иже идоша въ судехъ волгою даже до  града астарахани\" -> \"и же адоша въ судехъ колгою наже до  граду асдарахани\"\n",
      "[ERR:4] \"грамота о хлѣбныхъ запасехъ что послать въ борисоглебовъ\" -> \"примота о хлѣбныхъ запасехъ сто послать въ борисоглабовъ\"\n",
      "[ERR:10] \"во 2 день арсенію тверскому трезвонъ средней въ лебедь\" -> \"по 2 день посоніе туерскому трезвохъ сращнея въ лебедь\"\n",
      "[ERR:10] \"то бо  и лутшимъ прохлажденіемъ вашимь \" -> \"то же  и лотшимъ егославдеицехъ вашимь \"\n",
      "[ERR:9] \"и хозяинъ отвелъ мнѣ полату изрядную обитую всю кожами золотными\" -> \"а ходинъ отвелъ мнѣ полову изрядную обытсю всю кожами зохотноми\"\n",
      "[ERR:1] \"образъ  богородицы одегитріе обложенъ мѣдью окладъ и вѣнецъ басменные\" -> \"образъ богородицы одегитріе обложенъ мѣдью окладъ и вѣнецъ басменные\"\n",
      "[ERR:6] \"во мценескъ къ левонтью изволскому\" -> \"по дашнескъ къ левонтію изворскому\"\n",
      "[ERR:5] \"двѣ книги минеи  въ десть \" -> \"двѣ книгъ маніи  въ десая \"\n",
      "[OK] \"и поиде владимеръ къ кіеву на брата своего ерополка\" -> \"и поиде владимеръ къ кіеву на брата своего ерополка\"\n",
      "[ERR:3] \"на оборотѣ къ  челобитной по велѣнію андрюшки чамовсково симанко кузнецовъ руку приложилъ\" -> \"на оборотѣ къ  челобитной по велѣнію андрюшки чамовсково сиванка кузнецовъ руку прилгжилъ\"\n",
      "[ERR:7] \"5 сороковъ соболей по 40 р сорокъ\" -> \"и сороковъ шоболем по ма и строкъ\"\n",
      "[ERR:6] \"онофрей степановъ сынъ сергѣевъ\" -> \"ондрюшестепиновъ сынъ сергѣевъ\"\n",
      "[ERR:4] \"а  боярыни въ скамьѣ сидѣли\" -> \"а  боярыны въскамъ сидѣли\"\n",
      "[ERR:1] \"а сколько того хлѣба взято и то писано ниже сего\" -> \"а сколко того хлѣба взято и то писано ниже сего\"\n",
      "[ERR:8] \"и того имъ всего дано 34 руб 25 алтъ 2 денги\" -> \"и того ихъ всело чань 34 реб 20 асть 2 денги\"\n",
      "[OK] \"5 поясовъ шолковы розныхъ цвѣтовъ\" -> \"5 поясовъ шолковы розныхъ цвѣтовъ\"\n",
      "[ERR:5] \"о устроеніи градомъ и острогомъ въ сибирской земли\" -> \"и устроеніи грачомъ и остногомъ въ собирской зечли\"\n",
      "[ERR:9] \"первѣе христосъ взійде на небо спаситель да послется на землю духъ святъ утѣшитель\" -> \"первѣе христосъ війде на небоспаситѣлда поблетвя наземлюдухъ святъ утѣшитель\"\n",
      "[ERR:9] \"тово же  иде святославъ на дунай и на болгары и бившимся имъ обоимъ\" -> \"того же  изе святославъ на дуніе и та болгоры и бувшабся имъ обоимъ\"\n",
      "[ERR:2] \"иванъ павловъ сынъ кондыревъ\" -> \"иванъ пахвовъ сынъ кондыревъ\"\n",
      "[ERR:6] \"зотъ полозовъ семь рублевъ взялъ и росписался\" -> \"зотѣ полозамъ сець рублевъ взялъ и росписалмо\"\n",
      "[ERR:5] \"дати ся грамотка на москвѣ гсдрю братцу аверкею ивановичю кастереву\" -> \"датися грази отка на москвѣ гсдрю братца аверкею ивановичю кастереву\"\n",
      "[OK] \"писанъ на москвѣ  7140 іюня въ 22 день\" -> \"писанъ на москвѣ  7140 іюня въ 22 день\"\n",
      "[ERR:6] \"и ко кресту максимъ сунбуловъ приведенъ того жъ числа\" -> \"и ко креслу максимъ лунстровъ приведенъ того жъ чиста\"\n",
      "[ERR:6] \"на поляхъ стрійковскій листъ 617\" -> \"на поляхъ стрійе фоскей листъ 667\"\n",
      "[ERR:3] \"запонъ отласъ золотной тканъ въ шахматы на нем крестъ низанъ жемчюгомъ\" -> \"за понъ отласъ золотной тканъ въ шахматы на немкрестъ ни анъ жемчюгомъ\"\n",
      "[ERR:6] \"палецъ мученика лаврентія\" -> \"палица мыченика латрьятія\"\n",
      "[ERR:5] \"лоскутъ обьери дикаго цвѣту\" -> \"дойкутъ отьери дикаго цвати\"\n",
      "[ERR:2] \"5 пищалей желѣзныхъ полковыхъ\" -> \"опищалей желѣзныхъ полковыхъ\"\n",
      "[ERR:5] \"книга бесѣды апостолскіе на четырнадцать посланей печать литовская\" -> \"книга бесѣ ды за постолскіе начетырна дцать посланей печать литовская\"\n",
      "Character error rate: 10.484290%. Word error rate: 40.689802%. String accuracy: 12.842376%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=y_transformer_test_true,\n",
    "    y_pred=y_transformer_test_pred\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
